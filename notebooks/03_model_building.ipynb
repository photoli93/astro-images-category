{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7036d689",
   "metadata": {},
   "source": [
    "# Space Images Classifier - Using Kaggle dataset\n",
    "\n",
    "https://www.kaggle.com/datasets/abhikalpsrivastava15/space-images-category?utm_source=chatgpt.com\n",
    "\n",
    "### Notebook 3 - Building Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255efa75",
   "metadata": {},
   "source": [
    "# Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ec054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "# Add the root folder to Python's module search path\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\"))) \n",
    "# Import the project configuration\n",
    "from config import DEVICE, ORIGINAL_DATA_PATH, OUTPUT_PATH, IMG_SIZE, BATCH_SIZE, NUM_WORKERS, SEED, TRAIN_RATIO, VAL_RATIO, TEST_RATIO\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc9a1b",
   "metadata": {},
   "source": [
    "# Building model (EfficientNet-B0)\n",
    "\n",
    "https://medium.com/image-processing-with-python/efficientnetb0-architecture-stem-layer-496c7911a62d\n",
    "\n",
    "https://medium.com/@kdk199604/efficientnet-smarter-not-just-bigger-neural-networks-94db3e2f8699\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02640134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpaceClassifier(nn.Module):\n",
    "    \"\"\"EfficientNet-B0 based classifier for space images\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(SpaceClassifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained EfficientNet-B0\n",
    "        self.backbone = models.efficientnet_b0(pretrained=pretrained)\n",
    "        \n",
    "        # Freeze backbone during the first stage to speed up the training (avoid replacing pretrained features)\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Get the number of features output by the backbone before the original classifier\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        # Replace classifier default head\n",
    "        # Progressive reduction feature dimensionality (from 1280 default value to num_classes) and it helps for overfitting\n",
    "        # Introduction of non-linearity function between fully connected layers\n",
    "        # Use of higher dropout early and smaller later to help regularization of deeper layers and prevent overfitting as well\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    # Unfreeze backbone for fine-tuning\n",
    "    def unfreeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067d789",
   "metadata": {},
   "source": [
    "# Setting up training utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    # Init statistic variables\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"Validation\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Training utilities configured\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d57d7",
   "metadata": {},
   "source": [
    "# End of notebook 3 - Building Deep Learning model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
